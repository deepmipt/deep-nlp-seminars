{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the sake of reproducibility \n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN recap\n",
    "\n",
    "<img src=\"./pics/rnn.png\" width=\"90%\">\n",
    "\n",
    "Simplest RNN consisting of 1 layer receives $x_{(t)}$ and could be written as:\n",
    "\n",
    "$$y_{(t)} = \\phi (x_{(t)}^T \\cdot w_x + y_{(t-1)}^T \\cdot w_y + b)$$\n",
    "\n",
    "where \n",
    "* $x(t)$ -- input vector at time step _t_ \n",
    "* $y(t)$ -- output vector at time step _t_\n",
    "* $w_x$ -- weights vector for input \n",
    "* $w_y$ -- weights vector for output\n",
    "* $y(t-1)$ -- output vector at previous time step; for 0th step it's zero vector\n",
    "* $b$ -- bias\n",
    "* $\\phi$ -- some activation function, i.e. ReLU\n",
    "\n",
    "\n",
    "Also we should mention **hidden_state** ( $h(t)$ ) -- it's recurrent cell memory.\n",
    "\n",
    "In general case $h_{(t)} = f(h_{(t-1)}, x_{(t)})$, but also $y{(t)} = f(h{(t-1)}, x{(t)})$. So in this case $h(t) == y(t)$, but in practice more complex architectures are used, where **hidden_state** is not equal to the RNN output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Lets write simple RNN\n",
    "To write RNN we need to make few improvements to formula.\n",
    "\n",
    "Lets say that we have not only one vector $x_{(t)}$ as input, but a few vectors in mini-batch $X_{(t)}$ of size $m$ . So all consequent computaions will be in matrix form.\n",
    "\n",
    "$$ Y_{(t)} = \\phi(X_{(t)} \\cdot W_x + Y_{(t-1)} \\cdot W_y + b) = \\phi([X_{(t)} Y_{(t-1)}] \\cdot W + b) $$\n",
    "where\n",
    "$$ W = [W_x W_y]^T $$\n",
    "\n",
    "*It's matrix concatination in square brackets\n",
    "\n",
    "Dimentions:\n",
    "* $Y_{(t)}$ -- matrix [$m$ x n_neurons]\n",
    "* $X_{(t)}$ -- matrix [$m$ x n_features]\n",
    "* $b$ -- vector of size `n_neurons`\n",
    "* $W_x$ -- input weights of size [n_features x n_neurons]\n",
    "* $W_y$ -- output weights of size [n_neurons x n_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "n_neurons = 5\n",
    "\n",
    "# two time steps\n",
    "X0 = tf.placeholder(tf.float32, [None, n_features])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_features])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_features, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "# tanh as phi\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mini-batches of size 4\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])  # t = 0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])  # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Make the same computation using only one matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_features])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_features])\n",
    "\n",
    "< your code here >\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val_1, Y1_val_1 = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic_rnn\n",
    "\n",
    "In TensorFlow there is a function `tf.contrib.rnn.static_rnn` which create for each time step (unrolling) specific cell of desired type. Our implementation follows `tf.contrib.rnn.BasicRNNCell`. This implementation has such a drawback - we could need a lot of memory for long sequences. And because we want to work with such sequences we need to allocate a lot of memory at once. But in TF there is another option -- `dynamic_rnn`, where memory is allocated dynamically for each provided sequence, acording to its lenght.\n",
    "\n",
    "Lets rewrite the code with `dynamic_rnn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_features = 3\n",
    "n_neurons = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_features])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "X_batch = np.array([\n",
    "        # step 0     step 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instance 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instance 2 (padded with zero vectors)\n",
    "        [[6, 7, 8], [6, 5, 4]], # instance 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instance 4\n",
    "    ])\n",
    "\n",
    "# sequence lengths\n",
    "seq_length_batch = np.array([2, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs_val.shape)\n",
    "print(states_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the second sample there are zeros in output \n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but in state there are not\n",
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name generation\n",
    "\n",
    "Lets try to do something useful with our RNNs.\n",
    "\n",
    "_Teaser:_\n",
    "\n",
    "* It is hard to choose a name for a variable. But its much harder to choose a name for a person.\n",
    "  So lets make neural net do it instead!\n",
    "* Dataset consists of 8 thousand people names from different cultures all around the world.\n",
    "* Our toy task be to train a model to generate a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.readlines()\n",
    "    names = [start_token + name.lower() for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n samples = ', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x.strip().capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "Lets take all the latters disregarding a case + symbol ')' for the end of a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set = set()\n",
    "for name in names:\n",
    "    for letter in name:\n",
    "        token_set.add(letter)\n",
    "\n",
    "\n",
    "token_set.add(')')\n",
    "tokens = list(token_set)\n",
    "tokens.sort()\n",
    "\n",
    "print('n_tokens = ', len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {t: i for i, t in enumerate(tokens)}\n",
    "\n",
    "id_to_token = {i: t for i, t in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len, names)))\n",
    "\n",
    "# max length of a name in this dataset\n",
    "MAX_LEN = min([60, max(list(map(len, names)))])-1\n",
    "\n",
    "print(MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert symbols to their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_ix = list(map(lambda name: list(map(token_to_id.get, name + ')')), names))\n",
    "\n",
    "\n",
    "for i in range(len(names_ix)):\n",
    "    names_ix[i] = names_ix[i][:MAX_LEN+1] #crop too long\n",
    "    \n",
    "    if len(names_ix[i]) < MAX_LEN+1:\n",
    "        names_ix[i] += [token_to_id[\" \"]]*(MAX_LEN+1 - len(names_ix[i])) #pad too short\n",
    "        \n",
    "assert len(set(map(len, names_ix))) == 1\n",
    "\n",
    "names_ix = np.array(names_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_ix[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size):\n",
    "    \n",
    "    rows = data[np.random.randint(0, len(data), size=batch_size)]\n",
    "    x = rows[:, :-1]\n",
    "    y = rows[:, 1:]\n",
    "    \n",
    "    count = lambda r: np.sum([id_to_token[t] != ' ' for t in r])\n",
    "    lengths = list(map(count, x))\n",
    "    \n",
    "    return x, y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, length = sample_batch(names_ix, 10)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, None], name= 'X')\n",
    "y = tf.placeholder(tf.int32, [None, None], name = 'y')\n",
    "lengths = tf.placeholder(tf.int32, [None], name = 'lengths')\n",
    "learning_rate_ph = tf.placeholder(dtype=tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 60\n",
    "embedding_size = 8\n",
    "vocabulary_size = len(tokens)\n",
    "\n",
    "n_steps = MAX_LEN # this is number of unrollings\n",
    "\n",
    "\n",
    "embedding_mtx = < create matrix of embeddings >\n",
    "\n",
    "embed = < embed the input sequence >\n",
    "\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(< choose params >)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(< choose params >)\n",
    "\n",
    "pred_logits = < make logits >\n",
    "\n",
    "labels_one_hot = < make targets >\n",
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels_one_hot,\n",
    "    logits=pred_logits)\n",
    "    \n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "\n",
    "pred_probas = tf.nn.softmax(pred_logits)\n",
    "\n",
    "# sampling predictions of size [batch_size, num_steps]\n",
    "prediction = tf.argmax(pred_probas, axis=2)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate_ph).minimize(loss)\n",
    "\n",
    "# get the probability distribution for the last symbol\n",
    "# that will be needed for generation\n",
    "last_word_probas = pred_probas[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which params in network are being trained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generation a name\n",
    "\n",
    "* Lets take seed phrase\n",
    "* Predicting next token\n",
    "* Next token is being sampled from model predicted distribution \n",
    "* Token is added to seed phrase\n",
    "* Repeat (from step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(sess, seed_phrase=None, N=MAX_LEN, n_snippets=1):\n",
    "    \n",
    "    if seed_phrase is None:\n",
    "        seed_phrase = ' '\n",
    "    elif seed_phrase[0].isalpha():\n",
    "        seed_phrase = ' ' + seed_phrase\n",
    "    seed_phrase = seed_phrase.lower()\n",
    "    seed_phrase = np.array([token_to_id[tok] for tok in seed_phrase])\n",
    "    L = len(seed_phrase)\n",
    "    snippets = []\n",
    "    for _ in range(n_snippets):\n",
    "        x = np.zeros(N)\n",
    "        x[:len(seed_phrase)] = seed_phrase\n",
    "        for n in range(N - L):\n",
    "            feed_dict = {X: x[:L + n].reshape([1, -1]), lengths: [len(x)]}\n",
    "            p = sess.run(last_word_probas, feed_dict=feed_dict).reshape(-1)\n",
    "            ix = np.random.choice(np.arange(len(tokens)), p=p)\n",
    "            x[L + n] = ix\n",
    "        snippet = ''.join([id_to_token[idx] for idx in x])\n",
    "        if ')' in snippet:\n",
    "            upto = snippet.index(')')\n",
    "            snippet = snippet[:upto]\n",
    "        snippets.append(snippet.strip().capitalize())\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_pred(y_pred, k = 3):\n",
    "    for i in range(k):\n",
    "        print(\"\".join( [id_to_token[t] for t in y_pred[i,:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Session()\n",
    "    \n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "n_epochs = 5\n",
    "batches_per_epoch = 500\n",
    "batch_size = 10\n",
    "lr = 1e-2\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print(\">>Generated: \", generate_sample(s, n_snippets=6))\n",
    "    print(\"-------\\n\")\n",
    "    avg_cost = 0\n",
    "    for batch in range(batches_per_epoch):\n",
    "        x_, y_, len_ = sample_batch(names_ix, batch_size)\n",
    "\n",
    "        _, iloss, y_pred = s.run([train_op, loss, prediction], {X: x_,\n",
    "                                                                y: y_,\n",
    "                                                                lengths: len_,\n",
    "                                                                learning_rate_ph: lr})\n",
    "        avg_cost += iloss\n",
    "\n",
    "    print(\"EPOCH: \", epoch)\n",
    "    print(\"AVERAGE LOSS: \", avg_cost/batches_per_epoch)\n",
    "    print(\">>Predicted: \")\n",
    "    print_pred(y_pred)\n",
    "\n",
    "print(\">>Generated: \", generate_sample(s, n_snippets=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sample(s, seed_phrase='Puti', n_snippets=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sample(s, seed_phrase='Q', n_snippets=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sample(s, seed_phrase='Eug', n_snippets=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sample(s, seed_phrase='Lu', n_snippets=19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus part\n",
    "### Do more interesting stuff\n",
    "\n",
    "* Multi-layer (MultiRNNCell);\n",
    "* Try some other cell types: LSTM, GRU;\n",
    "* Try to generate tweet, using [this](http://study.mokoron.com) dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
